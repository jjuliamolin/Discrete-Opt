{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BpU0PTotQH_"
   },
   "source": [
    "\n",
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA231/DIT370 Discrete Optimization: Home Assignment 4 -- SDP and Maxcut** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Divya** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 15th March** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by:   Julia Molin, 950322-4124, mojulia@student.chalmers.se** <br />$\\qquad$ $\\qquad$$\\qquad$$\\qquad$$\\qquad$$\\quad$ **Ludwig Hultqvist, 970917-0071, ludhul@student.chalmers.se**<br />\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "General guidelines:\n",
    "*   All solutions to theoretical and pratical problems must be submitted in this ipynb notebook, and equations wherever required, should be formatted using LaTeX math-mode.\n",
    "*   All discussion regarding practical problems, along with solutions and plots should be specified in this notebook. All plots/results should be visible such that the notebook do not have to be run. But the code in the notebook should reproduce the plots/results if we choose to do so.\n",
    "*   Your name, personal number and email address should be specified above.\n",
    "*   All tables and other additional information should be included in this notebook.\n",
    "*   Before submitting, make sure that your code can run on another computer. That all plots can show on another computer including all your writing. It is good to check if your code can run here: https://colab.research.google.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2Ga2PmEtQIA"
   },
   "source": [
    "# Question 1.\n",
    "\n",
    "Consider the triangle graph i.e, three vertices all connected pairwise (unweighted, so each edge has weight $1$).\n",
    "\n",
    "* a. Write the $+1/-1$ labelling corresponding to a maximum cut and give the value of the cut.\n",
    "* b. Write the SDP relaxation of the MAXCUT problem for this specific graph: write the program explicitly without using summation signs, with the variables corresponding to a $3 \\times 3$ matrix, $X_{1,1,}, X_{1,2}, \\cdots$.\n",
    "* c. Solve the SDP by manual calculation (not using a SDP solver). (HINT: Use symmetry and then argue about when the matrix with $1$ as diagonal elements and $\\alpha$ in other positions is psd.)\n",
    "* d. Produce the vector labelling corresponding to the optimal solution of the SDP in (c). (HINT: for what angle is $\\cos \\theta = -1/2$?)\n",
    "* e. What is the expected value of the cut produced by rounding using the vector labels and a random hyperlane? Give a short justification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a)**\n",
    "\n",
    "Let $G = (V, E)$ be the fully connected undirected triangle graph with:\n",
    "\n",
    "$$\n",
    "V = \\{x_1, x_2, x_3\\} \\\\\n",
    "E = \\{e_1 = (x_1, x_2), e_2 = (x_1, x_3), e_3 = (x_2, x_3)\\} \\\\\n",
    "w_e = 1     \\ \\ \\ \\   \\forall e \\in E\n",
    "$$\n",
    "\n",
    "Since we have 3 vertices, there's only 3 possible partitions (cuts). No matter which of these we chose, the cut will always be crossing two edges. Since all edges has equal weight, we can choose the partition arbitrarly. The $+1/-1$ labelling of a maximum cut of G is then chosen as $x_1 = -1$ and $x_2 = x_3 = 1$. The max cut value $z^*$ is hence 2, computed as:\n",
    "\n",
    "$$\n",
    "z^* = 1(\\frac{1-x_1x_2}{2}) + 1(\\frac{1-x_1x_3}{2}) + 1(\\frac{1-x_2x_3}{2}) = \\frac{1}{2}(2 + 2 + 0) = 2\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b)**\n",
    "\n",
    "The MAXCUT problem of G is defined as the following optimization problem in a simplified form without summation signs.\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "\\max \\quad & \\frac{1}{2}(1-x_1x_2) + \\frac{1}{2}(1-x_1x_3) + \\frac{1}{2}(1-x_2x_3) \\\\\n",
    "\\textrm{s.t} \\quad \n",
    "&x_1, x_2, x_3 \\in \\{-1, 1\\} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "By introducing vectors $\\{v_1, v_2, v_3 \\in \\mathbb{R} : \\lvert\\lvert v \\lvert\\lvert = 1\\}$ for the vertices $x_1, x_2, x_3$, a $3 \\times 3$ positive semidefinite matrix of constrains $X$ can be introduced, as below, where every element $X_{ij} = v_i^Tv_j$. Using $X$, the SDP relaxation of the MAXCUT problem is expressed as following, where the objective function and constraints are linear in terms of $X_{ij}$.\n",
    "\n",
    "$$ \n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "X_{11} & X_{12} & X_{13} \\\\\n",
    "X_{21} & X_{22} & X_{23} \\\\\n",
    "X_{31} & X_{32} & X_{33} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "\\max \\quad &\n",
    "\\frac{1}{2}(1 - X_{11}) + \n",
    "\\frac{1}{2}(1 - X_{12}) + \n",
    "\\frac{1}{2}(1 - X_{13}) + \n",
    "\\frac{1}{2}(1 - X_{21}) + \n",
    "\\frac{1}{2}(1 - X_{22}) + \n",
    "\\frac{1}{2}(1 - X_{23}) +\n",
    "\\frac{1}{2}(1 - X_{31}) +\n",
    "\\frac{1}{2}(1 - X_{32}) + \n",
    "\\frac{1}{2}(1 - X_{33}) \\\\\n",
    "\\textrm{s.t} \\quad \n",
    "&X_{ii} = 1 \\\\\n",
    "&X \\succeq 0\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Per definition, the matrix $X$ is symmetric, i.e. $X_{ij} = X_{ji}$ for all $i,j$, and every diagonal element $X_{ii} = 1$, $X$. $X$ can hence be expressed as following. Using the new expression of $X$, the objective function of the SDP relaxation is simplified.\n",
    "\n",
    "$$ X =\n",
    "\\begin{bmatrix}\n",
    "1 & X_{12} & X_{13} \\\\\n",
    "X_{12} & 1 & X_{23} \\\\\n",
    "X_{13} & X_{23} & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}(1 - X_{11}) + \n",
    "\\frac{1}{2}(1 - X_{12}) + \n",
    "\\frac{1}{2}(1 - X_{13}) + \n",
    "\\frac{1}{2}(1 - X_{21}) + \n",
    "\\frac{1}{2}(1 - X_{22}) + \n",
    "\\frac{1}{2}(1 - X_{23}) +\n",
    "\\frac{1}{2}(1 - X_{31}) +\n",
    "\\frac{1}{2}(1 - X_{32}) + \n",
    "\\frac{1}{2}(1 - X_{33}) \\\\\n",
    "= \\frac{1}{2} (\n",
    "(1 - 1) + \n",
    "(1 - X_{12}) + \n",
    "(1 - X_{13}) + \n",
    "(1 - X_{12}) + \n",
    "(1 - 1) + \n",
    "(1 - X_{23}) +\n",
    "(1 - X_{13}) +\n",
    "(1 - X_{23}) + \n",
    "(1 - 1) )\\\\\n",
    "= \\frac{2}{2} (\n",
    "(1 - X_{12}) +\n",
    "(1 - X_{13}) +\n",
    "(1 - X_{23}) ) \\\\\n",
    "= 3 - X_{12} - X_{13} - X_{23}\n",
    "$$\n",
    "\n",
    "With the simplified objective function, the SDP relaxation is finally expressed as following.\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "\\max \\quad & 3 - X_{12} - X_{13} - X_{23} ,\\tag{1} \\\\\n",
    "\\textrm{s.t} \\quad \n",
    "&X \\succeq 0\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c)**\n",
    "\n",
    "A matrix A is positive semi definite if all it's eigenvalues $\\lambda$ are greater or equal to 0.\n",
    "We'll use the equation $det(X-\\lambda \\mathbf{I}) = 0$ to get a polynomal of X's eigenvalues. As proposed in the assignment we'll use a simplified version of X, resulting in the following determinant.\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "1      & \\alpha & \\alpha \\\\\n",
    "\\alpha & 1      & \\alpha \\\\\n",
    "\\alpha & \\alpha & 1      \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "det(X-\\lambda \\mathbf{i}) = det(\n",
    "\\begin{bmatrix}\n",
    "1 - \\lambda & \\alpha       & \\alpha \\\\\n",
    "\\alpha      & 1  - \\lambda & \\alpha \\\\\n",
    "\\alpha      & \\alpha       & 1 - \\lambda     \\\\\n",
    "\\end{bmatrix})\n",
    "$$\n",
    "\n",
    "By simplifying the expression and factorizing it, we reach an equivalent expression:\n",
    "$$\n",
    "\\begin{align}\n",
    "(1-\\lambda)((1-\\lambda)^2 - \\alpha) \n",
    "- \\alpha(\\alpha(1-\\lambda) - \\alpha^2)\n",
    "+ \\alpha(\\alpha^2 - (1-\\lambda)\\alpha)\n",
    "&= 0 \\implies \\\\\n",
    "(1-\\lambda)^3 - (1-\\lambda)(3\\alpha^2) + 2(\\alpha^3) &= 0 \\implies \\\\\n",
    "(\\alpha - (1- \\lambda))^2 \\ (2 \\alpha + (1-\\lambda)) &= 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We observe that the equation is equal to 0 if either factor is zero. We can hence infer expressions for $\\lambda_1$ from the first factor and $\\lambda_2$ from the second factor:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\lambda_1: \\ (\\alpha - (1- \\lambda))^2 = (\\alpha - 1 + \\lambda))^2 &= 0 \\implies\\\\\n",
    " \\alpha - 1 + \\lambda &= 0 \\implies \\\\\n",
    " \\lambda_1 &= 1 - \\alpha \\\\\n",
    "\\\\\n",
    "\\lambda_2: \\ 2 \\alpha  + 1 - \\lambda &= 0  \\implies\\\\\n",
    "\\lambda_2 &= 2 \\alpha + 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We use the inequality $\\lambda \\geq 0$ and can hence infer lower and upper bounds on $\\alpha$ using $\\lambda_1$ and $\\lambda_1$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\lambda &\\geq 0 \\implies \\\\\n",
    "\\lambda_1 &= 1 - \\alpha \\geq 0  \\\\\n",
    "\\alpha &\\leq 1\\\\\n",
    "\\\\\n",
    "\\lambda_2 &= 2 \\alpha + 1 \\geq 0 \\implies \\\\\n",
    "\\alpha &\\geq - \\frac{1}{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus, if matrix X should be p.s.d, $\\alpha$ must lie within the following range. Since $\\alpha$ is equivalent to every $X_{ij}$, every they must lie within the same range:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "- \\frac{1}{2} &\\leq  \\alpha \\leq 1    \\ \\ \\ \\  \\implies \\\\\n",
    "- \\frac{1}{2} &\\leq  X_{12}, X_{13}, X_{23} \\leq 1 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since the objective function (1) shall be maximized and the three variables are have negative coeficients, we actually want to minimize $X_{12}, X_{13}, X_{23}$. We thus set them to their lowest bound, resulting in the optimal solution $z*$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X_{1,2} = X_{1,3} = X_{2,3} &= -\\frac{1}{2} \\\\\n",
    "\\\\\n",
    "z^* = 3 + \\frac{3}{2} &= 4.5\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that in the objective function, every edge is counted twice since the graph is undirected. The optimal value is hence actually $\\frac{z*}{2}$:\n",
    "\n",
    "$$\n",
    "\\frac{z*}{2} = \\frac{4.5}{2} = 2.25\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1d)**\n",
    "The dot product of two vectors is equal to the product of it's norms and cos($\\theta$), where $\\theta$ is the angle between these vectors, as following. With unit vectors $\\mathbf{v}_i, \\mathbf{v}_j$, this is simply:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{a} \\cdot \\mathbf{b} &= |\\mathbf{a}| |\\mathbf{b}| cos(\\theta) \\\\\n",
    "\\mathbf{v}_i \\cdot \\mathbf{v}_j &= cos(\\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since $X_{ij} = v_i^T \\cdot v_j = - \\frac{1}{2}$ for the three variables $X_{12}, X_{13}, X_{23}$, we can compute the angle $\\theta$ between all three vectors as:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_i \\cdot \\mathbf{v}_j = cos(\\theta) \\\\\n",
    "\\cos^{-1}(\\mathbf{v}_i \\cdot \\mathbf{v}_j) = \\theta \\\\\n",
    "\\cos^{-1}(-\\frac{1}{2}) = \\theta \\\\\n",
    "\\theta = \\frac{2\\pi}{3} \n",
    "$$\n",
    "\n",
    "To extract the vectors $v_1, v_2, v_3$ from $X$, we use Cholesky decomposition. That is, we find the matrix $L$, such that $X = L L^T$. Here, $v_1, v_2, v_3$ will be the rows of $L$. For the $3\\times3$ matrix X, $L$ and $L^T$ will look has the shape: \n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & x_{12} & x_{13} \\\\\n",
    "x_{12} & 1 & x_{23} \\\\\n",
    "x_{13} & x_{23} & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\ \\ = \\ \\ \n",
    " \\begin{bmatrix}\n",
    "L_{11} &   0     &   0     \\\\\n",
    "L_{21} & L_{22} &   0     \\\\\n",
    "L_{31} & L_{32} & L_{33} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "L_{11} & L_{21} & L_{31}\\\\\n",
    "   0    & L_{22} & L_{23} \\\\\n",
    "   0    &    0    & L_{33} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From this, we can see that $v_1 = [L_{11}, 0, 0], v_2 = [L_{21}, L_{22}, 0], v_2 = [L_{31}, L_{32}, L_{32}]$ and that $X$ is equal to the matrix below. Further we can extract the $L_{ij}$ values with simple algebra:\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}   L_{11}^2 &   &(\\text{symmetric})   \\\\\n",
    "   L_{21}L_{11} & L_{21}^2 + L_{22}^2& \\\\\n",
    "   L_{31}L_{11} & L_{31}L_{21}+L_{32}L_{22} & L_{31}^2 + L_{32}^2+L_{33}^2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{L} = \n",
    "\\begin{bmatrix}\n",
    "\\sqrt{A_{11}} &  0 & 0  \\\\\n",
    "X_{21}/L_{11} & \\sqrt{X_{22} - L_{21}^2} & 0 \\\\\n",
    "X_{31}/L_{11} &  \\left(X_{32} - L_{31}L_{21} \\right) /L_{22}  &\\sqrt{X_{33}- L_{31}^2 - L_{32}^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The values of $L_{ij}$ is then extracted as following, which corresponds to the vectors:\n",
    "\n",
    "$$\n",
    "\\mathbf{L} = \n",
    "\\begin{bmatrix}\n",
    "\\sqrt{1} & 0                                   & 0  \\\\\n",
    "-0.5/1   & \\sqrt{1 - (-0.5)^2}                 & 0 \\\\\n",
    "-0.5/1   & \\left(-0.5 - (-0.5)^2\\right) /0.866 & \\sqrt{1- (-0.5)^2 - (-0.866)^2}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "1    & 0      & 0  \\\\\n",
    "-0.5 & 0.866  & 0 \\\\\n",
    "-0.5 & -0.866 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "v_1 &= \\begin{bmatrix} 1\\ \\ & \\ \\ \\ 0 \\ \\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ 0 \\end{bmatrix} \\\\\n",
    "v_2 &= \\begin{bmatrix} -0.5 &  0.866      & \\ \\ \\ 0 \\end{bmatrix} \\\\\n",
    "v_3 &= \\begin{bmatrix} -0.5 & -0.866      & 0 \\end{bmatrix} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "To finally get the labeling, we must pick a random unit vector $\\mathbf{q}$. Since we're doing this manually, we choose each value in $\\mathbf{q}$ as: $q_i = \\frac{1}{\\sqrt{3}} \\approx 0.577$. Since $\\mathbf{q}$ can have both positive and negative values, we arbitrary choose one of the three to be negative and the others positive. \n",
    "$q$ it thus chosen as following, where we obtain the labels for vertex $x_i$ from the corresponding unit vector $v_i$ as: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{q} &= \\begin{bmatrix} 0.577 & -0.577 & 0.577 \\end{bmatrix} \\\\\n",
    "x_i &=\n",
    "\\begin{cases} \n",
    "1 \\quad &\\text{if} \\ v_i \\cdot q \\geq 0 \\\\\n",
    "-1 \\quad &\\text{if} \\ v_i \\cdot q < 0 \n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Thus, our final labels are:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "v_1 \\cdot q &= 0.577 \\geq 0 &&\\implies x_1 = 1 \\\\\n",
    "v_2 \\cdot q &= -0.78 < 0 &&\\implies x_2 = -1 \\\\\n",
    "v_3 \\cdot q &=  0.21  \\geq 0 &&\\implies x_3 = 1 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**1e)**\n",
    "The Goemans Williamson algorithm is proven that the expected cut value is at least 0.878 the optimal solution. Thus, our rounded solution $\\tilde{z}$ is at least 0.878 times the actual optimal solution. This can be expressed as following:\n",
    "\n",
    "$$\n",
    "\\tilde{z} \\leq 0.878 z^*\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFec7wzqtQIB"
   },
   "source": [
    "# Question 2.\n",
    "\n",
    "\n",
    "* a. Implement the SDP relaxation for MAXCUT in CVXPY (https://www.cvxpy.org), see (https://www.cvxpy.org/examples/basic/sdp.html). (Unfortunately  the API for SDP in CVXOPT is not very convenient, so we are forced to use CVXPY. The best way if you have installation issues would be to use Google Colab, there you can directly start using it.)\n",
    "* b. Solve the SDP in the previous problem using (a).\n",
    "* c. Solve the SDP and give the MAXCUT value for for the random graph $G(100, 0,1)$. Give the approximation ratio of your solution to the optimal max-cut value.\n",
    "* d. Solve the SDP and give the MAXCUT value for the planted partition graph 'G' given below. Give the approximation ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for implementing SDP for Maxcut\n",
    "\n",
    "#### Formulate the Maxcut problem as SDP (recall lecture or refer to reference book [GM] in syllabus section)\n",
    "\n",
    "####  Once you obtain 'X' (the solution positive-semi-definite matrix from SDP, you may use Cholesky decomposition to get the solution unit-vectors, stacked as column vectors in 'U')\n",
    "\n",
    "```python\n",
    "Xnew = X.value\n",
    "eigs = np.linalg.eigh(Xnew)[0]\n",
    "if np.min(eigs) < 0:\n",
    "  Xnew = Xnew + (1.00001 * abs(min(eigs)) * np.identity(n_nodes))\n",
    "elif np.min(eigs) == 0:\n",
    "  Xnew = Xnew + 0.0000001 * np.identity(n_nodes)\n",
    "U = np.linalg.cholesky(Xnew).T\n",
    "```\n",
    "\n",
    "#### Round the unit-vectors to appropriate partition as explained in [GM] or class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a)** \n",
    "\n",
    "The SDP problem for arbitrary graphs can be specified as the following sum. However, to specify in a more CVXPY-friendly way, we can instead express the problem as the trace of the following matrix multiplication. Here, **W** is the matrix of edge-weights from the given graph while **1** is the matrix of 1's as every element. Using this definition, the method for computing Maxcuts are given below.\n",
    "\n",
    "$$\n",
    "z* = max \\ \\sum_{i,j} w_{i,j} \\ \\frac{1- X_{i,j}}{2} \\ \\ = \\frac{1}{2}trace \\ (\\mathbf{W}(\\mathbf{1}- \\mathbf{X}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def max_cut(G, print_variables=False):\n",
    "    '''\n",
    "    method for computing max cut of a given graph G\n",
    "    set print_variables to true for debugging\n",
    "    '''\n",
    "    # matrix of edge-weights / 2\n",
    "    W = G / 2\n",
    "    \n",
    "    # PSD matrix of variables\n",
    "    X = cp.Variable(G.shape, symmetric=True)\n",
    "    \n",
    "    # SDP relaxation objective function and constraints\n",
    "    objective = cp.Maximize(cp.trace(W @ (1 - X)))\n",
    "    constraints = [X >> 0, cp.diag(X) == np.ones(G.shape[0])]\n",
    "    \n",
    "    # SDP relaxation solution and variables\n",
    "    # divide by two since every X_ij is counted twice\n",
    "    z = cp.Problem(objective, constraints).solve() / 2\n",
    "    print(\"SDP relaxation optimal value: \", z)\n",
    "    if print_variables:\n",
    "        print(\"SDP relaxation optimal variables:\\n\", X.value)\n",
    "    \n",
    "    # Cholesky decomposition\n",
    "    U = X.value\n",
    "    I = np.identity(G.shape[0])\n",
    "    eigs = np.linalg.eigh(U)[0]\n",
    "    if np.min(eigs) < 0:\n",
    "        U += 1.00001 * abs(min(eigs)) * I\n",
    "    elif np.min(eigs) == 0:\n",
    "        U += 0.0000001 * I\n",
    "    U = np.linalg.cholesky(U).T\n",
    "    \n",
    "    # unit vectors of of SDP relaxation\n",
    "    if print_variables:\n",
    "        print(\"SDP relaxation unit vectors:\\n\", U)\n",
    "    \n",
    "    # uniformly chosen random vector\n",
    "    q = np.random.rand(G.shape[0]).T\n",
    "    q = q / np.linalg.norm(q)\n",
    "    \n",
    "    # rounded SDP relaxation solution and variables\n",
    "    x = [1 if v >= 0 else -1 for v in np.dot(q, U)]\n",
    "    # divide by 2 since every X_ij is counted twice\n",
    "    y = sum(w * (1 - x[i]*x[j]) for (i, j), w in np.ndenumerate(W)) / 2\n",
    "    print(\"SDP relaxation rounded optimal value: \", y)\n",
    "    if print_variables:\n",
    "        print(\"SDP relaxation rounded optimal variables:\\n\", x)\n",
    "    \n",
    "    # approximation ratio of SDP solution\n",
    "    print(\"SDP optimal approximation ratio: \", y / z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDP relaxation optimal value:  2.2499999998619593\n",
      "SDP relaxation optimal variables:\n",
      " [[ 1.  -0.5 -0.5]\n",
      " [-0.5  1.  -0.5]\n",
      " [-0.5 -0.5  1. ]]\n",
      "SDP relaxation unit vectors:\n",
      " [[ 1.00000000e+00 -5.00000000e-01 -5.00000000e-01]\n",
      " [ 0.00000000e+00  8.66025404e-01 -8.66025404e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  2.18066243e-05]]\n",
      "SDP relaxation rounded optimal value:  2.0\n",
      "SDP relaxation rounded optimal variables:\n",
      " [1, 1, -1]\n",
      "SDP optimal approximation ratio:  0.8888888889434234\n"
     ]
    }
   ],
   "source": [
    "# fully connected triangle matrix\n",
    "triangle = np.array([[0, 1, 1], \n",
    "                    [1, 0, 1], \n",
    "                    [1, 1, 0]])\n",
    "\n",
    "# compute SDP solution\n",
    "max_cut(triangle, print_variables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDP relaxation optimal value:  368.26560649626316\n",
      "SDP relaxation rounded optimal value:  335.0\n",
      "SDP optimal approximation ratio:  0.9096695268049673\n"
     ]
    }
   ],
   "source": [
    "# random graph from G(100, 0, 1)\n",
    "graph = np.loadtxt('../Lab2/graph.txt')\n",
    "\n",
    "# compute SDP solution\n",
    "max_cut(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDP relaxation optimal value:  20999.997487426495\n",
      "SDP relaxation rounded optimal value:  21000.0\n",
      "SDP optimal approximation ratio:  1.0000001196463717\n"
     ]
    }
   ],
   "source": [
    "# planted partition graph given in assignment\n",
    "adj_mat = np.array([[   0.  , 2., 1000.  ,  2. , 1000.  ,  2.  ,  2. ,1000.  ,  2.  ,  2.],\n",
    "                    [ 2.  ,  0. ,1000.  ,  2., 1000.  ,  2.  ,  2. ,1000.  ,  2.  ,  2.],\n",
    "                    [1000. , 1000.  ,  0. ,1000. ,   2. ,1000., 1000. ,   2. ,1000., 1000.],\n",
    "                    [   2.  ,  2. ,1000.  ,  0. ,1000.  ,  2. ,   2., 1000.  ,  2.  ,  2.],\n",
    "                    [1000., 1000.  ,  2. ,1000. ,   0., 1000. ,1000.  ,  2. ,1000. ,1000.],\n",
    "                    [   2.  ,  2., 1000.  ,  2., 1000. ,   0. ,   2., 1000. ,   2. ,   2.],\n",
    "                    [   2.  ,  2. ,1000.  ,  2. ,1000. ,   2. ,   0., 1000. ,   2. ,   2.],\n",
    "                    [1000.  ,1000.,    2. ,1000.,    2., 1000., 1000.,    0., 1000., 1000.],\n",
    "                    [   2. ,   2. ,1000. ,   2. ,1000. ,   2. ,   2., 1000.,    0.,    2.],\n",
    "                    [   2. ,   2. ,1000. ,   2. ,1000. ,   2. ,   2., 1000.,    2.,    0.]])\n",
    "\n",
    "max_cut(adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw2020-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
